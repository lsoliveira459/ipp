\documentclass[11pt,a4paper,onecolumn]{article}

\usepackage[brazilian]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{listings}
\usepackage{fullpage}
\usepackage{color, xcolor, indentfirst, tikz}
\usepackage{graphicx, caption, subcaption, standalone}
\usetikzlibrary{arrows,decorations.pathreplacing,matrix,calc}


\title{Relatório do Capítulo 06 de\\Introdução à Programação Paralela}
\author{Lucas Sousa de Oliveira (10/59491)}
\date{\today}

\lstdefinestyle{cc}{
  belowcaptionskip=1\baselineskip,
  breaklines=true,
  frame=l,
  xleftmargin=\parindent,
  language=C,
  showstringspaces=false,
  basicstyle=\footnotesize\ttfamily,
  keywordstyle=\bfseries\color{green!40!black},
  commentstyle=\itshape\color{purple!40!black},
  identifierstyle=\color{blue!50!black},
  stringstyle=\color{orange},
  numbers=left,
  stepnumber=1,
}
\lstdefinestyle{cbash}{
  breaklines=true,
  frame=l,
  language=bash,
  basicstyle=\footnotesize\ttfamily\color{orange},
  numbers=none,
  stepnumber=1,
  rulecolor=\color{black},
  belowcaptionskip=1\baselineskip,
  xleftmargin=\parindent,
}
\lstset{language=C}

\begin{document}
\maketitle

\section{Título do Capítulo}
\textit{Grouping Data For Communication}

\section{Objetivo}
Foi mencionado no capítulo 3 que na geração atual de sistemas paralelos, o envio de uma mensagem é uma operação custosa.
Uma consequencia natural disto é que, via de regra, quanto menos mensagens são enviadas, melhor o desempenho geral do programa.
Entretanto, em cada um dos nossos programas de cálculo da regra trapezoidal, quando distribuímos os dados, separamos "a", "b" e "n" em mensagens diferentes - seja com MPI\_Send e MPI\_Recv ou MPI\_Bcast.
Desta forma, podemos melorar a performance do nosso programa enviando vários dados em uma única mensagem.
MPI disponibiliza mecanismos para o agrupamento de dados individuais em uma única mensagem: o parametro \textit{count} em diversas rotinas de comunicação, tipos de dados derivados, e MPI\_Pack/MPI\_Unpack.
Examinaremos cada uma dessas opções a seguir.

\section{Resumo}
\label{sec:resumo}

Parei em 6.6

\section{Exercícios}
\subsection{Edite o programa da regra trapezoidal de forma que ele use Get\_data3.}
O programa com as modificações solicitadas encontra-se abaixo.
Note que o uso do tipo derivado com variáveis soltas não é muito bom uma vez que este tipo só poderá ser usado para aquela configuração específica de memória.
Se uma outra função quiser utilizar este tipo derivado, ela precisará redefinir o vetor de distancias (\textit{displacements}).
\lstinputlisting[style=cc]{../ex1/ex1_getdata3.c}

\subsection{Edite o programa da regra trapezoidal de forma que ele use Get\_data4.}
%\lstinputlisting[style=cc]{ex2_getdata4.c}

\subsection{Escreva um programa que cria um tipo derivado de dados para representar uma matrix esparça. Um entrada da matriz é uma estrutura contendo um ponto flutuante e dois inteiros. Os inteiros representam a linha e coluna de uma entrada cujo valor é dado pelo ponto flutuante. Teste seu tipo derivado usando um curto programa que o mande uma entrada de uma matriz de um processo para outro.}
O programa com as modificações solicitadas encontra-se abaixo.
Note que, como mencionado na questão 1, o uso do tipo derivado com variáveis soltas não é muito bom uma vez que este tipo só poderá ser usado para aquela configuração específica de memória.
Se uma outra função quiser utilizar este tipo derivado, ela precisará redefinir o vetor de distancias (\textit{displacements}).
Por causa disso, ao invés de lidar com variáveis soltas, elas foram agrupadas em uma estrutura.
O C garante que as informações contidas numa estrutura são armazenadas continuamente, o que nos garante que esta estrutura pode ser usadas por diversas funções de forma mais genérica que a anterior. 
\lstinputlisting[style=cc]{../ex3/ex3_sparse.c}

\subsection{Tendo em vista a regra de equivalencia de tipos, é possível para muitos tipos diferentes especificados por um remetente corresponderem a um dado tipo especificado pelo receptor. Considere um programa com as definições abaixo. Descreva brevemente a memória no processo 0 e no processo 1 referenciados por cada envio/recebimento. Quais recebimentos recebem que envios?}
\begin{lstlisting}[style=cc]
float        B[5][5];
float        x[5];
MPI_Datatype first_mpi_t;
MPI_Datatype second_mpi_t;
MPI_Datatype third_mpi_t;
int          blocklengths[5] = {1,1,1,1,1};      
int          displacements[5];

MPI_Type_contiguous(5, MPI_FLOAT, &first_mpi_t);
MPI_Type_vector(5, 1, 5, MPI_FLOAT, &second_mpi_t);
for (i = 0; i <5; i++)
    displacements[i] = 6*i;
MPI_Type_indexed(5, block_lengths, displacements, MPI_FLOAT, &third_mpi_t);

...

Process 0:
    MPI_Send(x, 5, MPI_FLOAT, 1, 0, MPI_COMM_WORLD);
    MPI_Send(&(B[1][0]), 5, MPI_FLOAT, 1, 0, MPI_COMM_WORLD);
    MPI_Send(x, 1, first_mpi_t, 1, 0, MPI_COMM_WORLD);
    MPI_Send(&(B[0][3]), 1, second_mpi_t, 1, 0, MPI_COMM_WORLD);
    MPI_Send(&(B[0][0]), 1, third_mpi_t, 1, 0, MPI_COMM_WORLD);
Process 1:
    MPI_Recv(x, 5, MPI_FLOAT, 0, 0, MPI_COMM_WORLD, &status);
    MPI_Recv(&(B[1][0]), 5, MPI_FLOAT, 0, 0, MPI_COMM_WORLD, &status);
    MPI_Recv(x, 1, first_mpi_t, 0, 0, MPI_COMM_WORLD, &status);
    MPI_Recv(&(B[0][1]), 1, second_mpi_t, 0, 0, MPI_COMM_WORLD, &status);
    MPI_Recv(&(B[0][0]), 1, third_mpi_t, 0, 0, MPI_COMM_WORLD, &status);
\end{lstlisting}

O primeiro envio do processo 0 envia os 5 elementos de $x$ para o $x$ do processo 1.
O segundo envio do processo 0 envia os primeiros 5 elementos da segunda linha de $B$ para o mesmo lugar da matriz $B$ no processo 1.
O terceiro envio do processo 0 envia os 5 elementos de $x$ para o $x$ do processo 1.
O quarto envio do processo 0 envia 5 elementos da quarta coluna de $B$ para a segunda coluna da $B$ do processo 1.
O quinto envio do processo 0 envia os 5 elementos $(i,j)$, onde $i = j$, para as mesmas posições na matriz $B$ do processo 1.

\section{Trabalhos de Programação}
\subsection{}
\subsection{}
\subsection{}

\section{Conclusão}
Conclui-se que a biblioteca MPI permite a distribuição de processamento entre diversos computadores, podendo assim aumentar o poder computacional diponível para um programa.
As ferramentas apresentadas aqui se mostraram extremamente úteis, apesar de simples, para as tarefas de computaçao paralela e distribuída.

\section{Referências}
\paragraph{Pacheco, P.S.,} (1997) \textit{Parallel Programming with MPI}. Morgan Kaufmann.

\end{document}